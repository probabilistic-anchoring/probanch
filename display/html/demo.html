<!DOCTYPE html>
<html>
<head>
  <title>ReGround demo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="./js/jquery-3.1.1.min.js"></script>
  <script src="http://cdn.robotwebtools.org/EventEmitter2/current/eventemitter2.min.js"></script>
  <script src="./js/roslib.min.js"></script>
  <link rel="stylesheet" href="./css/w3.css">
  <!--<link rel="stylesheet" href="http://www.w3schools.com/lib/w3.css">-->
  <style>
    body,h1,h2,h3,h4,h5 {font-family: "Arial", sans-serif}
    .header {
      border: 1px solid black;
      background-image: url(./images/network_header.jpg);
      background-position: right top;
      background-size: 535px 200px;
      background-repeat: no-repeat;
      padding: 0px;
    }
    .footer {
      background-image: url(./images/network_footer.jpg);
      background-position: right bottom;
      background-size: 318px 147px;
      background-repeat: no-repeat;
      padding: 0px;
      width: 318px;
      height: 147px;
    }
    li {
      border-bottom: 1px solid white;
      border-left: 1px solid white;
    }
    .active {
      background: #ffffff;
      color: #000000;
    }
    li a.menuItem:hover:not(.active) {
      background-color: black;
      color: white;
    }    
    li a.menuItem:hover {
      background-color: white;
      color: black;
    }    

  </style>
  <script>

   
    // Connecting to ROS
    // -----------------
    var ros = new ROSLIB.Ros();
  
    // Create a connection to the rosbridge WebSocket server.
    ros.connect('ws://localhost:9090');

    // ROS log
    ros.on( 'error', function(error) { 
      console.log( error ); 
    }); 
    ros.on('connection', function() { 
      console.log('Connection made!'); 
    });

    // Publisher/subscriber objects
    var talker = new ROSLIB.Topic({
      ros : ros,
      name : '/display/trigger',
      messageType : 'std_msgs/String'
    });
  
    var listener = new ROSLIB.Topic({
      ros : ros,
      name : '/display/base64img',
      messageType : 'std_msgs/String'
      //messageType : 'sensor_msgs/Image'
    });
  
    // Callback function for reciving an image
    listener.subscribe(function(message) {
      //console.log('Received message on ' + listener.name + ': ' + message.data);
      var imgData = "data:image/jpeg;base64," + message.data;
      //console.log(imgData);
      displayImg = document.getElementById("ROSImg");
      displayImg.style.display = "inline";
      displayImg.setAttribute( 'src', imgData);
    });

    // Text map for changing the describing text
    var dict_summary = {
      "segmentation" : 
      "<i>This object segmentation node is used in our framework for segmenting and detecting objects of interest in the scene.</i>",
      "tracking" : 
      "<i>The object tracking node is used to track and record swift movements in the scene.</i>",
      "extraction" : 
      "<i>The feature extraction node is responsible for extract both geometric and visual features of segmented objects.</i>",
      "classification" : 
      "<i>This symbol category classification procedure is initiated with the goal of symbolically associating a category label to each object.</i>",
      "grounding" : 
      "<i>In parallel with the category classification procedure is this predicate grounder node used for establishing the connection between measured attributes and semantic symbols.</i>",
      "anchoring" : 
      "<i>The object anchoring node is responsible for creating and maintaining consistent representations of objects, both in time and space.</i>",

    };

    var dict_body = {
      "segmentation" : 
      "The object segmentation method is based on point cloud data, which is given as input data by an RGB-D sensor. This method relies on organized point cloud data (i.e. the organization of point cloud data is identical to the rows and columns of the imagery data from which the point cloud originates). The whole segmentation procedure can briefly be described using the following steps: <ul><li>Estimate 3D surface normals based on integral images. This function uses the algorithm for calculating average 3D gradients over six integral images, where the horizontal and vertical 3D gradients are used to compute the normal as the cross-product between two gradients.</li><li>Planar segmentation based on the calculated surface normals, where the largest segmented plan is selected as the ground plane.</li> <li>Object segmentation through clustering of the remaining points (points that are not part of the detected planar surface). This segmentation uses a connected component segmentation, where a Euclidean comparison function is used to connect the components that constitute the cloud cluster of an individual object.</li></ul>",
      "tracking" : 
      "This object tracking procedure utilizes a particle filter-based tracking algorithm, which is included in the Point Cloud Library (<a href='http://pointclouds.org/'>PCL</a>). However, a drawback of such particle filter algorithm is that the algorithm is designed for tracking only one object of interest at a time. A pool of particle filters (one filter for each detected object) have therefore been employed in our system setup, and where only the particle filters in the approximation of scene movements are active during the tracking process.",
      "extraction" : 
      "The first step of the feature extraction node is to extract both a <i>shape attribute</i> as the 3D bounding box around each segmented object, and a 3D <i>position attribute</i> as the centre of the segmented point cloud. Next, both a <i>color attribute</i> and a <i>descriptor attribute</i> are extracted from each corresponding visual data of each segmented object. A color attribute is here measured as a color histogram (in the HSV color space). However, for the descriptor attribute, a more complicated procedure is invoked, which can be described using the following steps: <ul><li>Detect distinct image key-points through the use of the ORB key-point detector (Oriented FAST and Rotated BRIEF).</li><li>Extract binary feature descriptors by the use of the Fast Retina Keypoint (FREAK), in which a cascade of binary strings is computed as the intensities over retinal sampling patterns of a key-point patch.</li></ul>",
      "classification" : 
      "For this classification, we exploit recent advancements in deep learning through the <a href='http://caffe.berkeleyvision.org/'>Caffe deep learning framework</a>. The Convolutional Neural Network (CNN) architecture used in this case is based on the GoogLeNet model, which originally was trained on the ILSVRC 2012 data set. However, for our work, we have fine-tuned the model for objects categories that are relevant for a kitchen domain, e.g. <i>\'coffee mug\', \'spoon\', \'orange\', \'tomato\'</i>, etc. In the context of anchoring, we further assume that all trained object categories are part of the set of possible predicate symbols that the system have at disposal.",
      "grounding" : 
      "This predicate grounder is here responsible for grounding each measured attribute to a predicate grounding symbol, e.g. a certain peek in a color histogram, measured as a color attribute, is grounded to the symbol <i>\'red\'</i>. More specifically, we here rely on color theory and that a color <i>tone</i> is expressed as a mixture of the base color mixed with either <i>tint</i> (mixture of white) or <i>shade</i> (mixture of black), such that an elemental color term, e.g. <i>\'red\'</i>, can be defined as a set of color tones of different color shades of the (base) color term, e.g. <i>shades of red</i>. This information is publicly available on-line through <a href='https://en.wikipedia.org/wiki/List_of_colors_by_shade'>Wikipedia</a>. Our approach for grounding color predicates utilize this information in order to train a Support Vector Machine (SVM) classifier, which has been trained with sets of HSV color values for color shade of 13 elemental color terms (<i>\'white\', \'gray\', \'black\', \'magenta\', \'pink\', \'red\', \'brown\', \'orange\', \'yellow\', \'green\', \'cyan\', \'blue\',</i> and <i>\'violet\'</i>). Hence, the color predicate grounding is given by the color prediction of the most dominant peeks of the HSV color histogram that compose a color attribute.",
      "anchoring" : 
      "The entry point for the object anchoring node is a matching procedure. This procedure follows a bottom-up approach to perceptual anchoring, where the system constantly receives anchors and invokes a number of different matching algorithms (one matching algorithm for each measured attribute ) in order to determine if a candidate anchor has previously been perceived or not. Depending on the result of the matching procedure, anchors are subsequently maintained in memory through two functionalities:<ul><li><i>Acquire</i> -- stores a new anchor whenever a candidate anchor is received which currently does not match any attributes of an existing anchor.</li><li><i>Re-acquire</i> -- update an existing anchor whenever a candidate anchor is received which matches the attributes of an existing anchor. This functionality assures that the percepts pointed to by the anchor are the most recent and adequate perceptual representation of the object.</li></ul>"
    };


    // Handle menu item click 
    $(document).ready(function(){
      $("a.menuItem").click( function() {
        $("a.menuItem").removeClass("active");
        $(this).addClass("active");
        
        // Get the identifier 
        var key = $(this).attr('href').substring(1)
        
        // Set the title text
        var str = $(this).text();
        str = str.split(" ");
        str[0] = str[0].substring(0, 1) + str[0].substring(1).toLowerCase()
        str[1] = str[1].substring(0, 1) + str[1].substring(1).toLowerCase()
        $("h2.title").text(str[0] + " " + str[1]);

        // Set the summary and body text 
        $("p.summary").html(dict_summary[key])
        $("p.body").html(dict_body[key])

        // Create and send the ROS display trigger
        var str = new ROSLIB.Message({
          data : key
        });
        talker.publish(str);
      });
    });
  </script>
</head>
<body class="w3-white">

<!-- Header -->
<header class="header w3-container w3-top w3-black w3-padding-xxlarge">
    <h2 class="w3-xxxlarge" ><b>ReGround:</b></h2>
    <h3 class="w3-text-dark-grey w3-margin-0"><b>relational symbol grounding through affordance learning.</b></h3>
</header>

<!-- Menu - horizontal style -->
<ul class="w3-navbar w3-animate-left w3-center w3-black w3-text-grey w3-padding-0" style="width: 100%; position: fixed; top:180px; font-weight: bold">
  <li style="width: 16.666%; border-right: 1px solid white; border-left: 1px solid white;">
    <a href="#segmentation" class="w3-padding menuItem active">OBJECT SEGMENTATION</a>
  </li> 
  <li style="width: 16.666%; border-right: 1px solid white;">
    <a href="#tracking" class="w3-padding menuItem" >OBJECT TRACKING</a>
  </li>
  <li style="width: 16.666%; border-right: 1px solid white;">
    <a href="#extraction" class="w3-padding menuItem">FEATURE EXTRACTION</a>
  </li>
  <li style="width: 16.666%; border-right: 1px solid white;">
    <a href="#classification" class="w3-padding menuItem" >OBJECT CLASSIFICATION</a>
  </li>
  <li style="width: 16.666%; border-right: 1px solid white;">
    <a href="#grounding" class="w3-padding menuItem">SYMBOL GROUNDING</a>
  </li>
  <li style="width: 16.666%; border-right: 1px solid white;">
    <a href="#anchoring" class="w3-padding menuItem">OBJECT ANCHORING</a>
  </li>
</ul>

<!-- Menu - vertical style 
<ul class="w3-sidenav w3-animate-left w3-center w3-black w3-text-grey w3-padding-0" style="width: 250px; font-weight: bold">
  <li>
    <a href="#segmentation" class="w3-padding menuItem active">OBJECT SEGMENTATION</a>
  </li> 
  <li>
    <a href="#tracking" class="w3-padding menuItem" >OBJECT TRACKING</a>
  </li>
  <li>
    <a href="#extraction" class="w3-padding menuItem">FEATURE EXTRACTION</a>
  </li>
  <li>
    <a href="#classificiation" class="w3-padding menuItem" >OBJECT CLASSIFICATION</a>
  </li>
  <li>
    <a href="#grounding" class="w3-padding menuItem">SYMBOL GROUNDING</a>
  </li>
  <li>
    <a href="#anchoring" class="w3-padding menuItem">OBJECT ANCHORING</a>
  </li>
</ul>
-->

<!-- Page content -->
<div class="w3-main w3-padding" style="margin-top: 230px;">
  <div class="w3-container w3-margin" style="float: left;">
    <img id="ROSImg" src="" alt="ROS response image..." style="width: 960px; height: 540px; border: 1px solid black; display: none;">
  </div> 
  <div class="w3-container" style="width: 40%; float: left; margin-top: 32px;">
    <h2 class="title" style="font-weight: bold; text-decoration: underline;"></h2>
    <p class="summary"></p>
    <p class="body"></p>
  </div>
   <div class="footer w3-container" style="position: absolute; bottom: 0px; right: 0px; height: 147px; padding: 0px; z-index: -1;"></div>
</div>

<!-- Footer -->
 <footer class="w3-container w3-bottom w3-white w3-text-black" style="width: 50%">
   <div class="w3-container w3-border-top w3-border-black" style="float: left; width: 100%">
     <p style="float: left; font-weight: bold;">
       &copy; ReGround (2016) :: Andreas Persson (andres.persson@oru.se)
     </p>
   </div>


   <!-- Logo navbar 
   <div class="w3-container" style="position: fixed; bottom: 0px; right: 0px; height: 105px; padding: 0px;">
     <img src="network_footer.jpg" alt="Footer" style="width: 212px; height: 105px;">
   </div>

   <ul class="w3-navbar w3-white w3-hover-white w3-padding-small" style="position: fixed; bottom: 0px; right: 0px; width: 50%;">
     <li style="float: right;">
       <a href="https://www.oru.se/english/">  
	 <img class="logo" src="oru_logo.svg" alt="ORU" style="height: 48px">
       </a>
     </li>
     <li style="float: right;">
       <a href="https://www.kuleuven.be/english">  
	 <img class="logo" src="kul_logo.png" alt="KULeuven" style="height: 48px">
       </a>
     </li>
     <li style="float: right;">
       <a href="https://www.ku.edu.tr/en">  
	 <img class="logo" src="koc_logo.jpg" alt="KOC" style="height: 48px">
       </a>
     </li>
     <li style="float: right;">
       <a href="http://www.chistera.eu/">  
	 <img class="logo" src="chist_logo.gif" alt="Chist-Era" style="height: 48px">
       </a>
     </li>
     
   </ul>
   -->
</footer> 


</body>
</html>
